{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "systematic-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import pycountry\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spanish-twenty",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    }
   ],
   "source": [
    "pdfFileObj = open('commencement2021.pdf', 'rb')\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "pages = pdfReader.numPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "found-sacramento",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shanghai : 30\n",
      "Beijing : 28\n",
      "Wuhan : 14\n",
      "Hangzhou : 13\n",
      "Shenzhen : 12\n",
      "Chengdu : 12\n",
      "Nanjing : 10\n",
      "Suzhou : 6\n",
      "Guangzhou : 5\n",
      "Luoyang : 4\n",
      "Tianjin : 4\n",
      "Wenzhou : 3\n",
      "Changzhou : 3\n",
      "Taiyuan : 3\n",
      "Daqing : 3\n",
      "Shenyang : 3\n",
      "Chongqing : 3\n",
      "Nantong : 3\n",
      "Ningbo : 3\n",
      "Yangzhou : 3\n",
      "Changchun : 2\n",
      "Shijiazhuang : 2\n",
      "Jiujiang : 2\n",
      "Yantai : 2\n",
      "Meishan : 2\n",
      "Yueyang : 2\n",
      "Fuzhou : 2\n",
      "Changsha : 2\n",
      "Foshan : 2\n",
      "Yizheng : 2\n",
      "Zhuhai : 2\n",
      "Hefei : 2\n",
      "Baoding : 2\n",
      "Ganzhou : 2\n",
      "Jiangyin : 2\n",
      "Jinan : 2\n",
      "Qingdao : 2\n",
      "Wuxi : 2\n",
      "Quzhou : 1\n",
      "Hongze : 1\n",
      "WuGang : 1\n",
      "Taizhou : 1\n",
      "Maoming : 1\n",
      "Xiaogan : 1\n",
      "Changzhi : 1\n",
      "Lianyungang : 1\n",
      "Xiamen : 1\n",
      "Nanchang : 1\n",
      "Laixi : 1\n",
      "Huaian : 1\n",
      "Weinan : 1\n",
      "Yancheng : 1\n",
      "Shangrao : 1\n",
      "Shiyan : 1\n",
      "Hebi : 1\n",
      "Wuhu : 1\n",
      "Liaocheng : 1\n",
      "Chuzhou : 1\n",
      "Changde : 1\n",
      "Dingzhou : 1\n",
      "Anshan : 1\n",
      "Zhengzhou : 1\n",
      "Handan : 1\n",
      "Harbin : 1\n",
      "Shaoxing : 1\n",
      "Zhoushan : 1\n",
      "Zibo : 1\n",
      "Xiantao : 1\n",
      "Xuzhou : 1\n",
      "Xinxiang : 1\n",
      "Zhuji : 1\n",
      "Fuyang : 1\n",
      "Tangshan : 1\n",
      "HuZhou : 1\n",
      "Jinjiang : 1\n",
      "Nanning : 1\n",
      "Kunming : 1\n",
      "Jinhua : 1\n"
     ]
    }
   ],
   "source": [
    "cities = {}\n",
    "for p in range(pages):\n",
    "    pageObj = pdfReader.getPage(p)\n",
    "    text = pageObj.extractText()\n",
    "    pattern = re.compile(r'Ł \\w+, China')\n",
    "    results = pattern.findall(text)\n",
    "    for result in results:\n",
    "        city = result[2:-7]\n",
    "        if city not in cities.keys():\n",
    "            cities[city] = 1\n",
    "        else:\n",
    "            cities[city] += 1\n",
    "sorted_cities = {k: v for k, v in sorted(cities.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "for item in sorted_cities.items():\n",
    "    print(item[0],':',item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nearby-metadata",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "country_name_list = [] \n",
    "for item in list(pycountry.countries):\n",
    "    name = str(item.name)\n",
    "    if ',' in name:\n",
    "        idx = name.index(',')\n",
    "        name = name[:idx]\n",
    "    if '(' in name:\n",
    "        idx = name.index('(')\n",
    "        name = name[:idx-1]\n",
    "    country_name_list.append(name)\n",
    "country_name_list = set(country_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "celtic-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ''\n",
    "for p in range(pages):\n",
    "    pageObj = pdfReader.getPage(p)\n",
    "    text = pageObj.extractText()\n",
    "    texts += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "legitimate-saver",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States : 2799\n",
      "China : 273\n",
      "India : 123\n",
      "Canada : 55\n",
      "Mexico : 51\n",
      "Korea : 49\n",
      "Singapore : 45\n",
      "France : 31\n",
      "United Kingdom : 28\n",
      "Turkey : 23\n",
      "Germany : 23\n",
      "Taiwan : 23\n",
      "Brazil : 22\n",
      "Italy : 19\n",
      "Japan : 15\n",
      "Colombia : 13\n",
      "Chile : 13\n",
      "Iran : 13\n",
      "Greece : 12\n",
      "Australia : 11\n",
      "Hong Kong : 11\n",
      "New Zealand : 10\n",
      "Nigeria : 10\n",
      "Niger : 10\n",
      "Israel : 10\n",
      "Indonesia : 10\n",
      "Peru : 9\n",
      "Russian Federation : 8\n",
      "Thailand : 8\n",
      "Ghana : 8\n",
      "Spain : 8\n",
      "Venezuela : 7\n",
      "Philippines : 7\n",
      "Viet Nam : 7\n",
      "South Africa : 7\n",
      "Lebanon : 6\n",
      "Saudi Arabia : 6\n",
      "Sweden : 6\n",
      "Egypt : 6\n",
      "Argentina : 5\n",
      "Ethiopia : 5\n",
      "Puerto Rico : 5\n",
      "Bangladesh : 5\n",
      "Romania : 5\n",
      "Pakistan : 5\n",
      "Poland : 5\n",
      "Jamaica : 4\n",
      "Kenya : 4\n",
      "San Marino : 4\n",
      "Netherlands : 4\n",
      "Ireland : 4\n",
      "Belgium : 4\n",
      "Virgin Islands : 3\n",
      "Chad : 3\n",
      "Kazakhstan : 3\n",
      "Mongolia : 3\n",
      "Austria : 3\n",
      "Malaysia : 3\n",
      "Jordan : 3\n",
      "Switzerland : 3\n",
      "Uruguay : 3\n",
      "Myanmar : 2\n",
      "Costa Rica : 2\n",
      "Mali : 2\n",
      "El Salvador : 2\n",
      "Cyprus : 2\n",
      "Guatemala : 2\n",
      "Norway : 2\n",
      "Sri Lanka : 2\n",
      "Rwanda : 2\n",
      "Ecuador : 2\n",
      "Ukraine : 2\n",
      "Botswana : 2\n",
      "Afghanistan : 2\n",
      "Luxembourg : 2\n",
      "Dominica : 2\n",
      "Iceland : 2\n",
      "Portugal : 2\n",
      "Tunisia : 2\n",
      "Denmark : 2\n",
      "Nicaragua : 2\n",
      "Trinidad and Tobago : 1\n",
      "Algeria : 1\n",
      "Dominican Republic : 1\n",
      "Angola : 1\n",
      "Bermuda : 1\n",
      "Serbia : 1\n",
      "Eritrea : 1\n",
      "Nepal : 1\n",
      "Syrian Arab Republic : 1\n",
      "Morocco : 1\n",
      "Qatar : 1\n",
      "Northern Mariana Islands : 1\n",
      "United Arab Emirates : 1\n",
      "Azerbaijan : 1\n",
      "Zimbabwe : 1\n",
      "Paraguay : 1\n",
      "Bahamas : 1\n",
      "Guam : 1\n",
      "Tanzania : 1\n",
      "Finland : 1\n",
      "Tajikistan : 1\n"
     ]
    }
   ],
   "source": [
    "keys = country_name_list\n",
    "count = {}\n",
    "for key in keys:\n",
    "    key = '(,|Ł) ' + key\n",
    "    pattern = re.compile(key)\n",
    "    result = pattern.findall(texts)\n",
    "    if len(result) > 0:\n",
    "        count[key[6:]] = len(result)\n",
    "sorted_countries = {k: v for k, v in sorted(count.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "print('United States',':', 2799)\n",
    "for item in sorted_countries.items():\n",
    "    if 'Georgia' in item[0]:\n",
    "        continue\n",
    "    print(item[0],':',item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "closed-indian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1193"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums = 0 \n",
    "for item in sorted_countries.items():\n",
    "    sums += item[1]\n",
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "broke-mouth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California : 995\n",
      "Texas : 185\n",
      "New York : 179\n",
      "Illinois : 112\n",
      "Washington : 103\n",
      "Massachusetts : 90\n",
      "Pennsylvania : 76\n",
      "New Jersey : 74\n",
      "Virginia : 73\n",
      "Florida : 68\n",
      "Colorado : 67\n",
      "Maryland : 65\n",
      "Oregon : 55\n",
      "Georgia : 53\n",
      "Arizona : 52\n",
      "North Carolina : 41\n",
      "Michigan : 40\n",
      "Minnesota : 38\n",
      "Ohio : 37\n",
      "Indiana : 34\n",
      "Wisconsin : 31\n",
      "Connecticut : 28\n",
      "Utah : 27\n",
      "New Mexico : 22\n",
      "Nevada : 22\n",
      "Missouri : 21\n",
      "Iowa : 20\n",
      "Tennessee : 19\n",
      "District of Columbia : 15\n",
      "Hawaii : 15\n",
      "Kentucky : 12\n",
      "Kansas : 11\n",
      "Oklahoma : 10\n",
      "Louisiana : 9\n",
      "Montana : 8\n",
      "Vermont : 8\n",
      "Maine : 8\n",
      "Nebraska : 7\n",
      "Idaho : 7\n",
      "Alabama : 7\n",
      "Arkansas : 7\n",
      "Mississippi : 6\n",
      "Alaska : 6\n",
      "Rhode Island : 5\n",
      "South Carolina : 5\n",
      "Puerto Rico : 5\n",
      "New Hampshire : 4\n",
      "West Virginia : 4\n",
      "Virgin Islands : 3\n",
      "North Dakota : 3\n",
      "South Dakota : 2\n",
      "Delaware : 2\n",
      "Northern Mariana Islands : 1\n",
      "Guam : 1\n",
      "Wyoming : 1\n"
     ]
    }
   ],
   "source": [
    "state_list = []\n",
    "for state in list(pycountry.subdivisions.get(country_code='US')):\n",
    "    state_list.append(state.name)\n",
    "count = {}\n",
    "keys = state_list\n",
    "for key in keys:\n",
    "    pattern = re.compile(key)\n",
    "    result = pattern.findall(texts)\n",
    "    if len(result) > 0:\n",
    "        count[key] = len(result)\n",
    "sorted_states = {k: v for k, v in sorted(count.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "for item in sorted_states.items():\n",
    "    print(item[0],':',item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "junior-senior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2799"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums = 0 \n",
    "for item in sorted_states.items():\n",
    "    sums += item[1]\n",
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "facial-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://en.wikipedia.org/wiki/List_of_cities_in_China'\n",
    "file=urllib.request.urlopen(url)\n",
    "data=file.read().decode()\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "\n",
    "city_province = {}\n",
    "for child in soup.find_all(title=\"Beijing\")[1].parent.parent.parent.find_all('tr')[3:]:\n",
    "    if len(child.find_all('a')) >= 2:\n",
    "        city_province[child.a.string] = child.find_all('a')[1].string\n",
    "    if len(child.find_all('a')) == 1:\n",
    "        city_province[child.a.string] = child.a.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "thrown-classification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hongze\n",
      "WuGang\n",
      "Huaian\n",
      "HuZhou\n"
     ]
    }
   ],
   "source": [
    "province_count = {item[1]:0 for item in city_province.items()}\n",
    "for item in sorted_cities.items():\n",
    "    if item[0] in city_province.keys():\n",
    "        province_count[city_province[item[0]]] += item[1]\n",
    "    else:\n",
    "        print(item[0])\n",
    "sorted_provinces = {k: v for k, v in sorted(province_count.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "artificial-occasions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jiangsu : 36\n",
      "Shanghai : 30\n",
      "Beijing : 28\n",
      "Zhejiang : 26\n",
      "Guangdong : 22\n",
      "Hubei : 17\n",
      "Sichuan : 14\n",
      "Shandong : 9\n",
      "Jiangxi : 8\n",
      "Hebei : 7\n",
      "Henan : 7\n",
      "Anhui : 5\n",
      "Hunan : 6\n",
      "Tianjin : 4\n",
      "Liaoning : 4\n",
      "Heilongjiang : 4\n",
      "Shanxi : 4\n",
      "Chongqing : 3\n",
      "Fujian : 2\n",
      "Jilin : 2\n",
      "Guangxi : 1\n",
      "Shaanxi : 1\n",
      "Yunnan : 1\n",
      "Gansu : 0\n",
      "Guizhou : 0\n",
      "Qinghai : 0\n",
      "Hainan : 0\n",
      "Inner Mongolia : 0\n",
      "Ningxia : 0\n",
      "Tibet : 0\n",
      "Xinjiang : 0\n"
     ]
    }
   ],
   "source": [
    "sorted_provinces['Jiangsu'] += 1\n",
    "sorted_provinces['Hunan'] += 1\n",
    "sorted_provinces['Jiangsu'] += 1\n",
    "sorted_provinces['Zhejiang'] += 1\n",
    "\n",
    "for item in sorted_provinces.items():\n",
    "    print(item[0],':',item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-prevention",
   "metadata": {},
   "source": [
    "Phd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "extensive-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = texts.index('Naomi Marisa Fa-Kaji')\n",
    "a2 = texts.index('Katherine Amelia Holmes')\n",
    "b1 = texts.index('Salem Saad Aldousary')\n",
    "b2 = texts.index('Salome Aguilar Llanes')\n",
    "c1 = texts.index('Liam Aiello')\n",
    "c2 = texts.index('King Castillo Alandy Dy')\n",
    "d1 = texts.index('Amin Aalipour')\n",
    "d2 = texts.index('Alexandra V. Akre')\n",
    "e1 = texts.index('Branden Adams')\n",
    "e2 = texts.index('Hui Xiang Koh')\n",
    "f1 = texts.index('Claudio Alfonso Fuentes Maureira')\n",
    "f2 = texts.index('Alexis Marie Amano')\n",
    "g1 = texts.index('Diana Julia Chang')\n",
    "doctor_texts = texts[a1:a2] + texts[b1:b2] + texts[c1:c2] + texts[d1:d2] + texts[e1:e2] + texts[f1:f2] + texts[g1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bibliographic-milton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beijing : 6\n",
      "Shanghai : 5\n",
      "Wuhan : 4\n",
      "Chengdu : 3\n",
      "Yangzhou : 3\n",
      "Jiujiang : 2\n",
      "Suzhou : 2\n",
      "Luoyang : 2\n",
      "Tianjin : 2\n",
      "Jinan : 2\n",
      "Wenzhou : 2\n",
      "Hangzhou : 2\n",
      "Quzhou : 1\n",
      "Hongze : 1\n",
      "Shenzhen : 1\n",
      "WuGang : 1\n",
      "Shijiazhuang : 1\n",
      "Meishan : 1\n",
      "Changchun : 1\n",
      "Guangzhou : 1\n",
      "Handan : 1\n",
      "Harbin : 1\n",
      "Shaoxing : 1\n",
      "Nantong : 1\n",
      "Chongqing : 1\n",
      "Zhoushan : 1\n",
      "Zibo : 1\n",
      "Xiantao : 1\n",
      "Xuzhou : 1\n",
      "Changsha : 1\n",
      "Xinxiang : 1\n",
      "Zhuji : 1\n",
      "Fuyang : 1\n",
      "Ganzhou : 1\n",
      "Qingdao : 1\n",
      "Hefei : 1\n",
      "Nanning : 1\n",
      "Kunming : 1\n",
      "Yantai : 1\n",
      "Wuxi : 1\n",
      "Ningbo : 1\n",
      "Jinhua : 1\n",
      "Fuzhou : 1\n"
     ]
    }
   ],
   "source": [
    "cities = {}\n",
    "pattern = re.compile(r'Ł \\w+, China')\n",
    "results = pattern.findall(doctor_texts)\n",
    "for result in results:\n",
    "    city = result[2:-7]\n",
    "    if city not in cities.keys():\n",
    "        cities[city] = 1\n",
    "    else:\n",
    "        cities[city] += 1\n",
    "sorted_cities_doctor = {k: v for k, v in sorted(cities.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "for item in sorted_cities_doctor.items():\n",
    "    print(item[0],':',item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "forbidden-consistency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States : 599\n",
      "China : 80\n",
      "India : 32\n",
      "Canada : 19\n",
      "Korea : 16\n",
      "Germany : 10\n",
      "Singapore : 10\n",
      "Italy : 9\n",
      "Taiwan : 9\n",
      "Iran : 9\n",
      "Mexico : 8\n",
      "France : 5\n",
      "Chile : 5\n",
      "Israel : 5\n",
      "Brazil : 4\n",
      "New Zealand : 3\n",
      "Hong Kong : 3\n",
      "Lebanon : 3\n",
      "Thailand : 3\n",
      "Turkey : 3\n",
      "Greece : 3\n",
      "Egypt : 3\n",
      "Japan : 3\n",
      "Russian Federation : 2\n",
      "Australia : 2\n",
      "Kazakhstan : 2\n",
      "United Kingdom : 2\n",
      "Jordan : 2\n",
      "Philippines : 2\n",
      "Saudi Arabia : 2\n",
      "Poland : 2\n",
      "Nigeria : 1\n",
      "Argentina : 1\n",
      "Jamaica : 1\n",
      "Algeria : 1\n",
      "Angola : 1\n",
      "Niger : 1\n",
      "Colombia : 1\n",
      "Cyprus : 1\n",
      "Peru : 1\n",
      "Austria : 1\n",
      "Norway : 1\n",
      "Sri Lanka : 1\n",
      "Switzerland : 1\n",
      "Ecuador : 1\n",
      "Puerto Rico : 1\n",
      "Spain : 1\n",
      "Bangladesh : 1\n",
      "Dominica : 1\n",
      "United Arab Emirates : 1\n",
      "Netherlands : 1\n",
      "Ireland : 1\n",
      "Viet Nam : 1\n",
      "Nicaragua : 1\n",
      "Pakistan : 1\n",
      "Belgium : 1\n"
     ]
    }
   ],
   "source": [
    "keys = country_name_list\n",
    "count = {}\n",
    "\n",
    "for key in keys:\n",
    "    key = '(,|Ł) ' + key\n",
    "    pattern = re.compile(key)\n",
    "    result = pattern.findall(doctor_texts)\n",
    "    if len(result) > 0:\n",
    "        count[key[6:]] = len(result)\n",
    "sorted_countries_doctor = {k: v for k, v in sorted(count.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "print('United States',':', 599)\n",
    "for item in sorted_countries_doctor.items():\n",
    "    if 'Georgia' in item[0]:\n",
    "        continue\n",
    "    print(item[0],':',item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "solar-sunglasses",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums = 0 \n",
    "for item in sorted_countries_doctor.items():\n",
    "    sums += item[1]\n",
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "occupational-inventory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California : 181\n",
      "New York : 36\n",
      "Texas : 29\n",
      "Illinois : 27\n",
      "Massachusetts : 25\n",
      "Washington : 22\n",
      "New Jersey : 21\n",
      "Virginia : 20\n",
      "Pennsylvania : 19\n",
      "Arizona : 16\n",
      "Florida : 15\n",
      "Colorado : 14\n",
      "Wisconsin : 14\n",
      "Maryland : 14\n",
      "Michigan : 11\n",
      "Ohio : 11\n",
      "Utah : 10\n",
      "North Carolina : 10\n",
      "Iowa : 10\n",
      "Minnesota : 9\n",
      "Georgia : 9\n",
      "Indiana : 9\n",
      "Oregon : 9\n",
      "New Mexico : 8\n",
      "Missouri : 6\n",
      "Connecticut : 5\n",
      "Tennessee : 4\n",
      "Oklahoma : 4\n",
      "District of Columbia : 3\n",
      "Louisiana : 3\n",
      "Maine : 3\n",
      "Montana : 2\n",
      "Hawaii : 2\n",
      "Rhode Island : 2\n",
      "Nevada : 2\n",
      "Kansas : 2\n",
      "Kentucky : 2\n",
      "Arkansas : 2\n",
      "Delaware : 1\n",
      "Vermont : 1\n",
      "New Hampshire : 1\n",
      "West Virginia : 1\n",
      "South Carolina : 1\n",
      "Alaska : 1\n",
      "Puerto Rico : 1\n",
      "Alabama : 1\n"
     ]
    }
   ],
   "source": [
    "state_list = []\n",
    "for state in list(pycountry.subdivisions.get(country_code='US')):\n",
    "    state_list.append(state.name)\n",
    "count = {}\n",
    "\n",
    "keys = state_list\n",
    "for key in keys:\n",
    "    pattern = re.compile(key)\n",
    "    result = pattern.findall(doctor_texts)\n",
    "    if len(result) > 0:\n",
    "        count[key] = len(result)\n",
    "sorted_states_doctor = {k: v for k, v in sorted(count.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "for item in sorted_states_doctor.items():\n",
    "    print(item[0],':',item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "powerful-familiar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums = 0 \n",
    "for item in sorted_states_doctor.items():\n",
    "    sums += item[1]\n",
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dirty-travel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hongze\n",
      "WuGang\n"
     ]
    }
   ],
   "source": [
    "province_count = {item[1]:0 for item in city_province.items()}\n",
    "for item in sorted_cities_doctor.items():\n",
    "    if item[0] in city_province.keys():\n",
    "        province_count[city_province[item[0]]] += item[1]\n",
    "    else:\n",
    "        print(item[0])\n",
    "sorted_provinces_doctor = {k: v for k, v in sorted(province_count.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "brutal-affairs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zhejiang : 10\n",
      "Jiangsu : 9\n",
      "Beijing : 6\n",
      "Shanghai : 5\n",
      "Hubei : 5\n",
      "Shandong : 5\n",
      "Jiangxi : 4\n",
      "Sichuan : 4\n",
      "Henan : 3\n",
      "Tianjin : 2\n",
      "Anhui : 2\n",
      "Guangdong : 2\n",
      "Hebei : 2\n",
      "Chongqing : 1\n",
      "Guangxi : 1\n",
      "Heilongjiang : 1\n",
      "Hunan : 2\n",
      "Jilin : 1\n",
      "Yunnan : 1\n",
      "Gansu : 0\n",
      "Fujian : 0\n",
      "Shaanxi : 0\n",
      "Guizhou : 0\n",
      "Qinghai : 0\n",
      "Hainan : 0\n",
      "Liaoning : 0\n",
      "Inner Mongolia : 0\n",
      "Ningxia : 0\n",
      "Shanxi : 0\n",
      "Tibet : 0\n",
      "Xinjiang : 0\n"
     ]
    }
   ],
   "source": [
    "sorted_provinces_doctor['Jiangsu'] += 1\n",
    "sorted_provinces_doctor['Hunan'] += 1\n",
    "\n",
    "for item in sorted_provinces_doctor.items():\n",
    "    print(item[0],':',item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-spending",
   "metadata": {},
   "source": [
    "bachelor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "crazy-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = texts.index('Katherine Amelia Holmes')\n",
    "a2 = texts.index('Devon Rae Burger')\n",
    "b1 = texts.index('King Castillo Alandy Dy')\n",
    "b2 = texts.index('Pablo Antonio Absalon')\n",
    "c1 = texts.index('Alexandra V. Akre')\n",
    "c2 = texts.index('Gabriela Andicoechea Fischmann')\n",
    "bachelor_texts = texts[a1:a2] + texts[b1:b2] + texts[c1:c2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "indirect-sapphire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shanghai : 4\n",
      "Shenzhen : 4\n",
      "Beijing : 2\n",
      "Changzhou : 1\n",
      "Yantai : 1\n",
      "Nanjing : 1\n",
      "Yueyang : 1\n",
      "Hangzhou : 1\n",
      "Chengdu : 1\n"
     ]
    }
   ],
   "source": [
    "cities = {}\n",
    "pattern = re.compile(r'Ł \\w+, China')\n",
    "results = pattern.findall(bachelor_texts)\n",
    "for result in results:\n",
    "    city = result[2:-7]\n",
    "    if city not in cities.keys():\n",
    "        cities[city] = 1\n",
    "    else:\n",
    "        cities[city] += 1\n",
    "sorted_cities_bachelor = {k: v for k, v in sorted(cities.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "for item in sorted_cities_bachelor.items():\n",
    "    print(item[0],':',item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "focused-namibia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States : 1094\n",
      "India : 22\n",
      "China : 18\n",
      "United Kingdom : 17\n",
      "Singapore : 13\n",
      "Canada : 11\n",
      "Korea : 10\n",
      "Mexico : 9\n",
      "Turkey : 7\n",
      "Italy : 5\n",
      "Brazil : 5\n",
      "Hong Kong : 4\n",
      "France : 4\n",
      "Viet Nam : 4\n",
      "Virgin Islands : 3\n",
      "Philippines : 3\n",
      "Puerto Rico : 3\n",
      "Ghana : 3\n",
      "Taiwan : 3\n",
      "Indonesia : 3\n",
      "South Africa : 3\n",
      "New Zealand : 2\n",
      "Argentina : 2\n",
      "Jamaica : 2\n",
      "Kenya : 2\n",
      "Chad : 2\n",
      "Mongolia : 2\n",
      "Venezuela : 2\n",
      "Malaysia : 2\n",
      "San Marino : 2\n",
      "Spain : 2\n",
      "Luxembourg : 2\n",
      "Germany : 2\n",
      "Sweden : 2\n",
      "Iran : 2\n",
      "Japan : 2\n",
      "Nigeria : 1\n",
      "Russian Federation : 1\n",
      "Australia : 1\n",
      "Trinidad and Tobago : 1\n",
      "Myanmar : 1\n",
      "Niger : 1\n",
      "Costa Rica : 1\n",
      "Bermuda : 1\n",
      "Colombia : 1\n",
      "Serbia : 1\n",
      "El Salvador : 1\n",
      "Cyprus : 1\n",
      "Peru : 1\n",
      "Norway : 1\n",
      "Ethiopia : 1\n",
      "Chile : 1\n",
      "Rwanda : 1\n",
      "Thailand : 1\n",
      "Saudi Arabia : 1\n",
      "Botswana : 1\n",
      "Israel : 1\n",
      "Greece : 1\n",
      "Netherlands : 1\n",
      "Zimbabwe : 1\n",
      "Tunisia : 1\n",
      "Bahamas : 1\n",
      "Guam : 1\n",
      "Nicaragua : 1\n",
      "Finland : 1\n",
      "Egypt : 1\n",
      "Poland : 1\n"
     ]
    }
   ],
   "source": [
    "keys = country_name_list\n",
    "count = {}\n",
    "\n",
    "for key in keys:\n",
    "    key = '(,|Ł) ' + key\n",
    "    pattern = re.compile(key)\n",
    "    result = pattern.findall(bachelor_texts)\n",
    "    if len(result) > 0:\n",
    "        count[key[6:]] = len(result)\n",
    "sorted_countries_bachelor = {k: v for k, v in sorted(count.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "print('United States',':', 1094)\n",
    "for item in sorted_countries_bachelor.items():\n",
    "    if 'Georgia' in item[0]:\n",
    "        continue\n",
    "    print(item[0],':',item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "discrete-citizenship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums = 0 \n",
    "for item in sorted_countries_bachelor.items():\n",
    "    sums += item[1]\n",
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cloudy-swaziland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California : 422\n",
      "Texas : 79\n",
      "New York : 57\n",
      "Washington : 44\n",
      "Illinois : 35\n",
      "Florida : 30\n",
      "Pennsylvania : 30\n",
      "Colorado : 29\n",
      "Oregon : 29\n",
      "Georgia : 25\n",
      "New Jersey : 25\n",
      "Massachusetts : 24\n",
      "Arizona : 23\n",
      "Virginia : 21\n",
      "Maryland : 19\n",
      "Minnesota : 14\n",
      "Connecticut : 13\n",
      "Nevada : 13\n",
      "Michigan : 11\n",
      "Indiana : 11\n",
      "Utah : 10\n",
      "Wisconsin : 10\n",
      "Ohio : 10\n",
      "North Carolina : 9\n",
      "District of Columbia : 8\n",
      "New Mexico : 8\n",
      "Hawaii : 7\n",
      "Tennessee : 6\n",
      "Missouri : 5\n",
      "Nebraska : 5\n",
      "Iowa : 5\n",
      "Kentucky : 5\n",
      "Mississippi : 4\n",
      "Idaho : 4\n",
      "Kansas : 4\n",
      "Arkansas : 4\n",
      "Montana : 3\n",
      "Virgin Islands : 3\n",
      "Vermont : 3\n",
      "Rhode Island : 3\n",
      "Oklahoma : 3\n",
      "Puerto Rico : 3\n",
      "Alabama : 3\n",
      "Maine : 3\n",
      "North Dakota : 2\n",
      "Louisiana : 2\n",
      "Alaska : 2\n",
      "Delaware : 1\n",
      "Guam : 1\n",
      "New Hampshire : 1\n",
      "West Virginia : 1\n",
      "Wyoming : 1\n",
      "South Carolina : 1\n"
     ]
    }
   ],
   "source": [
    "state_list = []\n",
    "for state in list(pycountry.subdivisions.get(country_code='US')):\n",
    "    state_list.append(state.name)\n",
    "count = {}\n",
    "\n",
    "keys = state_list\n",
    "for key in keys:\n",
    "    pattern = re.compile(key)\n",
    "    result = pattern.findall(bachelor_texts)\n",
    "    if len(result) > 0:\n",
    "        count[key] = len(result)\n",
    "sorted_states_bachelor = {k: v for k, v in sorted(count.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "for item in sorted_states_bachelor.items():\n",
    "    print(item[0],':',item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "activated-participation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1094"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums = 0 \n",
    "for item in sorted_states_bachelor.items():\n",
    "    sums += item[1]\n",
    "sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-vegetation",
   "metadata": {},
   "source": [
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "whole-estimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shanghai : 21\n",
      "Beijing : 20\n",
      "Wuhan : 10\n",
      "Hangzhou : 10\n",
      "Nanjing : 9\n",
      "Chengdu : 8\n",
      "Shenzhen : 7\n",
      "Suzhou : 4\n",
      "Guangzhou : 4\n",
      "Taiyuan : 3\n",
      "Daqing : 3\n",
      "Shenyang : 3\n",
      "Luoyang : 2\n",
      "Tianjin : 2\n",
      "Changzhou : 2\n",
      "Chongqing : 2\n",
      "Nantong : 2\n",
      "Ningbo : 2\n",
      "Foshan : 2\n",
      "Yizheng : 2\n",
      "Zhuhai : 2\n",
      "Baoding : 2\n",
      "Jiangyin : 2\n",
      "Wenzhou : 1\n",
      "Changchun : 1\n",
      "Shijiazhuang : 1\n",
      "Meishan : 1\n",
      "Yueyang : 1\n",
      "Fuzhou : 1\n",
      "Changsha : 1\n",
      "Hefei : 1\n",
      "Ganzhou : 1\n",
      "Qingdao : 1\n",
      "Wuxi : 1\n",
      "Taizhou : 1\n",
      "Maoming : 1\n",
      "Xiaogan : 1\n",
      "Changzhi : 1\n",
      "Lianyungang : 1\n",
      "Xiamen : 1\n",
      "Nanchang : 1\n",
      "Laixi : 1\n",
      "Huaian : 1\n",
      "Weinan : 1\n",
      "Yancheng : 1\n",
      "Shangrao : 1\n",
      "Shiyan : 1\n",
      "Hebi : 1\n",
      "Wuhu : 1\n",
      "Liaocheng : 1\n",
      "Chuzhou : 1\n",
      "Changde : 1\n",
      "Dingzhou : 1\n",
      "Anshan : 1\n",
      "Zhengzhou : 1\n",
      "Tangshan : 1\n",
      "HuZhou : 1\n",
      "Jinjiang : 1\n"
     ]
    }
   ],
   "source": [
    "count = sorted_cities.copy()\n",
    "for key in count:\n",
    "    if key in sorted_cities_doctor.keys():\n",
    "        count[key] -= sorted_cities_doctor[key]\n",
    "    if key in sorted_cities_bachelor.keys():\n",
    "        count[key] -= sorted_cities_bachelor[key]\n",
    "count = {item[0]:item[1] for item in count.items() if item[1]!=0}\n",
    "        \n",
    "sorted_cities_master = {k: v for k, v in sorted(count.items(), key=lambda item: item[1], reverse=True)}\n",
    "for item in sorted_cities_master.items():\n",
    "    print(item[0],':',item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-intervention",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
